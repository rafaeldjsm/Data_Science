{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLTK.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ymvp5LthRzmU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import PlaintextCorpusReader"
      ],
      "metadata": {
        "id": "1ysXmDDTNLpP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_root = '/content'\n",
        "machado = PlaintextCorpusReader(corpus_root, '.*')\n",
        "machado.fileids()"
      ],
      "metadata": {
        "id": "YCfyRpOyVOL0",
        "outputId": "fc369a2a-a7f0-4ad9-db03-39f84491cea6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config/.last_opt_in_prompt.yaml',\n",
              " '.config/.last_survey_prompt.yaml',\n",
              " '.config/.last_update_check.json',\n",
              " '.config/active_config',\n",
              " '.config/config_sentinel',\n",
              " '.config/configurations/config_default',\n",
              " '.config/gce',\n",
              " '.config/logs/2021.12.23/14.31.34.537359.log',\n",
              " '.config/logs/2021.12.23/14.31.54.176680.log',\n",
              " '.config/logs/2021.12.23/14.32.11.074637.log',\n",
              " '.config/logs/2021.12.23/14.32.17.600672.log',\n",
              " '.config/logs/2021.12.23/14.32.35.447923.log',\n",
              " '.config/logs/2021.12.23/14.32.36.119106.log',\n",
              " 'domcasmurro.txt',\n",
              " 'memriaspstumasdebrscubas.txt',\n",
              " 'quincasborba.txt',\n",
              " 'sample_data/README.md',\n",
              " 'sample_data/anscombe.json',\n",
              " 'sample_data/california_housing_test.csv',\n",
              " 'sample_data/california_housing_train.csv',\n",
              " 'sample_data/mnist_test.csv',\n",
              " 'sample_data/mnist_train_small.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dom = machado.raw(\"domcasmurro.txt\")\n",
        "bras = machado.raw(\"memriaspstumasdebrscubas.txt\")\n",
        "borba = machado.raw(\"quincasborba.txt\")"
      ],
      "metadata": {
        "id": "vmNPkJXjVbSX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dom)"
      ],
      "metadata": {
        "id": "OEnVGuYO44kp",
        "outputId": "65f4114e-ca61-466d-c883-1638846d6bb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto1 = machado.words('domcasmurro.txt')\n",
        "\n",
        "print(texto1)\n",
        "len(texto1)"
      ],
      "metadata": {
        "id": "srhMGzPeXjRH",
        "outputId": "57fa69b9-1929-4b08-f44b-fc12d896cce8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'Do', 'titulo', '.', 'Uma', 'noite', 'destas', ...]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82046"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.text import Text\n",
        "\n",
        "domcasmurro =Text(texto1)\n",
        "\n",
        "\n",
        "domcasmurro.concordance('Bentinho')\n",
        "\n"
      ],
      "metadata": {
        "id": "GryH6U3MvUaI",
        "outputId": "53a20603-15f5-4b75-9929-b8e4fc7d9d6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 25 of 56 matches:\n",
            "ersiste na ideia de metter o nosso Bentinho no seminario ? É mais que tempo , \n",
            ". Não me parece bonito que o nosso Bentinho ande mettido nos cantos com a filh\n",
            ". Em segredinhos , sempre juntos . Bentinho quasi que não sae de lá . A pequen\n",
            " faça desconfiar . Basta a edade ; Bentinho mal tem quinze annos . Capitú fez \n",
            "dre , tem - se ganho o principal . Bentinho ha de satisfazer os desejos de sua\n",
            " -- Estavamos , sim , senhor , mas Bentinho ri logo , não aguenta . -- Quando \n",
            "tantes . -- Pois que outra cousa , Bentinho ? -- Neste caso , peço - lhe um fa\n",
            "zer : « José Dias , preciso metter Bentinho no seminario .» Timidez não é tão \n",
            "eus estudos . -- Estamos a bordo , Bentinho , estamos a bordo ! XXVII Ao portã\n",
            "a isso por mim , sim ? Você quer , Bentinho ? -- Mamãe querendo . -- Quero , m\n",
            "i zangado . -- Bem , cedo ao nosso Bentinho , suspirou o pae de Capitú . Pela \n",
            "ei o meu sonho imperial : -- Não , Bentinho , deixemos o imperador socegado , \n",
            "ferno isto ! Você teime com elle , Bentinho . -- Teimo ; hoje mesmo elle ha de\n",
            " - se para mim : -- Prepara - te , Bentinho ; tu pódes vir a ser protonotario \n",
            " perguntava em voz alta : -- Mas , Bentinho , que ó protonotario apostolico ? \n",
            " despediu - se . -- Vae com ella , Bentinho , disse minha mãe . -- Não precisa\n",
            "é que agora ...? Não creio , não , Bentinho . E depois ... Vocação ? Mas a voc\n",
            "não lhe hei de mentir nem faltar , Bentinho ; são cousas que não se fazem sem \n",
            "so , não me deixaria assim , não , Bentinho ; eu sei que seria castigada e bem\n",
            "bispo , dizem ... Deixa de manha , Bentinho . Creio que os olhos que lhe deite\n",
            " -- Não , não peço . Estás tonto , Bentinho ? E como havia de saber que Deus m\n",
            " ! -- Eu ? Mas ... -- Não é nada , Bentinho . Pois quem é que ha de dar pancad\n",
            "ios , e abanou a cabeça . -- Não , Bentinho , disse , seria esperar muito temp\n",
            "ase com outra ? -- Tudo póde ser , Bentinho . Você póde achar outra moça que l\n",
            "o a vocação ecclesiastica do nosso Bentinho se manifesta clara e decisiva . Ha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bigramas - sequência de duas palavras\n",
        "\n",
        "from nltk import bigrams\n",
        "list(bigrams(['O', 'Direção', 'concursos', 'oferece', 'preparação', 'de', 'elite']))\n"
      ],
      "metadata": {
        "id": "vtoVoW9iw8KP",
        "outputId": "9d4ea446-5023-4ba6-8973-f054842b9c8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('O', 'Direção'),\n",
              " ('Direção', 'concursos'),\n",
              " ('concursos', 'oferece'),\n",
              " ('oferece', 'preparação'),\n",
              " ('preparação', 'de'),\n",
              " ('de', 'elite')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "machado.words('domcasmurro.txt').collocations()"
      ],
      "metadata": {
        "id": "p_M0AsZv67qG",
        "outputId": "4e68a749-cacf-48a8-e2bb-81e681b0ba26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-bc148f541442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmachado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'domcasmurro.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollocations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'StreamBackedCorpusView' object has no attribute 'collocations'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import collocations\n",
        "#encontrar colocações(bigramas)\n",
        "\n",
        "text = nltk.Text(dom)\n",
        "\n",
        "text.collocations()"
      ],
      "metadata": {
        "id": "LaMtKNonyTeU",
        "outputId": "63e6083d-5428-4a06-813f-934c080fdc74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-0a0523a59c4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollocations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/text.py\u001b[0m in \u001b[0;36mcollocations\u001b[0;34m(self, num, window_size)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;31m#print(\"Building collocations list\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mignored_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m             \u001b[0mfinder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigramCollocationFinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0mfinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_freq_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "#tokenizacao\n",
        "\n",
        "sentence = \"O Direção Concursos oferece preparação de elite para concursos.\"\n",
        "\n",
        "tokens = word_tokenize(sentence)\n",
        "\n",
        "tokens"
      ],
      "metadata": {
        "id": "NZapzkcX1IIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#construindo um tagger\n",
        "#Importa a biblioteca\n",
        "nltk.download('mac_morpho')\n",
        "from nltk.corpus import mac_morpho\n",
        "#Carrega as sentença rotuladas do Corpus\n",
        "sentencas_etiquetadas = mac_morpho.tagged_sents()"
      ],
      "metadata": {
        "id": "RTOs6TLw1j4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentencas_etiquetadas)\n"
      ],
      "metadata": {
        "id": "O2yeZzE32nLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags = [tag for (word, tag) in mac_morpho.tagged_words()]\n"
      ],
      "metadata": {
        "id": "rJdX78D14Maa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nltk.FreqDist(tags).most_common(20)"
      ],
      "metadata": {
        "id": "nR91oU_84qkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto = 'O Direção Concursos é o melhor curso preparatório para concursos'\n",
        "tokens = word_tokenize(texto)\n",
        "unigram_tagger = nltk.tag.UnigramTagger(sentencas_etiquetadas)\n",
        "unigram_tagger.tag(tokens)"
      ],
      "metadata": {
        "id": "TJme-8gW4xDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bigramas e trigramas para treinar\n",
        "\n",
        "from nltk.tag.sequential import DefaultTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
        "t0=DefaultTagger('N')\n",
        "t1=UnigramTagger(sentencas_etiquetadas, backoff=t0)\n",
        "t2=BigramTagger(sentencas_etiquetadas, backoff=t1)\n",
        "t3=TrigramTagger(sentencas_etiquetadas, backoff=t2)\n"
      ],
      "metadata": {
        "id": "cGmPAvj16zoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#após treinamento\n",
        "t3.tag(tokens)\n",
        "\n"
      ],
      "metadata": {
        "id": "uYvXm5Zd75Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separando sentenças\n",
        "sentencasdodom= nltk.sent_tokenize(dom)\n",
        "palavrasdodom= [nltk.word_tokenize(sent) for sent in sentencasdodom]\n",
        "palavrastageadas = [t3.tag(word) for word in palavrasdodom]\n",
        "print(palavrastageadas)"
      ],
      "metadata": {
        "id": "o-piIZ5QS2BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#regexp_tokenize - baseado em expressões regulares\n",
        "\n",
        "\n",
        "# Módulos\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "# Padrao regex para encontrar palavras\n",
        "pattern1 = r\"W\\w+\"\n",
        "\n",
        "palavrascomW = regexp_tokenize(dom, pattern1)\n",
        "print(palavrascomW)\n",
        "\n"
      ],
      "metadata": {
        "id": "hneR9TkJcSXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PREPROCESSAMENTO\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "tokens_dom = word_tokenize(dom)\n",
        "\n",
        "tokens_dom_minusculas = [t.lower() for t in tokens_dom]\n",
        "\n",
        "cesta_de_palavras = Counter(tokens_dom_minusculas)\n",
        "\n",
        "print(cesta_de_palavras.most_common(10))"
      ],
      "metadata": {
        "id": "cGv-8L0Mv01S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_dom_alfabetica = [w for w in tokens_dom_minusculas if w.isalpha()]\n",
        "\n",
        "cesta_alfabetica = Counter(tokens_dom_alfabetica)\n",
        "\n",
        "print(cesta_alfabetica.most_common(10))"
      ],
      "metadata": {
        "id": "UJN_IcVe2ty0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stopwordsPT = nltk.corpus.stopwords.words('portuguese')\n",
        "stopwordsPT[:10]"
      ],
      "metadata": {
        "id": "4yIYBOyDXcsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_dom_pronto = [w for w in tokens_dom_alfabetica if w not in stopwordsPT]\n",
        "\n",
        "cesta_pronta = Counter(tokens_dom_pronto)\n",
        "\n",
        "print(cesta_pronta.most_common(20))"
      ],
      "metadata": {
        "id": "h7hjIdpW2g2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming. #RSLPStemmer em português, WordNetLemmatizer em inglês\n",
        "nltk.download('rslp')\n",
        "from nltk.stem import RSLPStemmer\n",
        "\n",
        "\n",
        "stemmer = RSLPStemmer()\n",
        "stemmer.stem(\"casamento\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yp8g2KUv6Ni4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fluxo ampliado preprocessamento\n",
        "from nltk.stem import RSLPStemmer\n",
        "from collections import Counter\n",
        "\n",
        "#Tokens\n",
        "tokens_dom = word_tokenize(dom)\n",
        "\n",
        "# Lower words: lower_only\n",
        "lower_only = [t.lower() for t in tokens_dom]\n",
        "\n",
        "# Retain alphabetic words: alpha_only\n",
        "alpha_only = [t for t in lower_only if t.isalpha()]\n",
        "\n",
        "# Remove all stop words: no_stops\n",
        "no_stops = [t for t in alpha_only if t not in stopwordsPT]\n",
        "\n",
        "# Instantiate the RSLPStemmer\n",
        "stemmer = RSLPStemmer()\n",
        "\n",
        "# Stem all tokens into a new list: stemmed\n",
        "stemmed = [stemmer.stem(t) for t in no_stops]\n",
        "\n",
        "# Create the bag-of-words: bow\n",
        "bow = Counter(stemmed)\n",
        "\n",
        "# Print the 10 most common tokens\n",
        "print(bow.most_common(10))"
      ],
      "metadata": {
        "id": "6CkNAvVb7RHs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}